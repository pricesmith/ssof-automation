# ssof-automation

## Problem Space / Context?

Despite how quickly technologies can evolve within even a single company, we still all too often become and remain somewhat tunnel-visioned on the progress itself unknowingly bound to the tools and processes already in place, even when these tools and processes revolve around rapid development and rapid evolution. The philosophies, practices, and procedures imposed on our approach to data in rapidly moving environments is, more often than not, nothing different. In some slightly stronger words, we largely, and probably somewhat globally, underappreciate the extent to which our handling and interpretation of, and our synthesis with data influences and affects decision-making. The tools we've come to use to deal with data aims, on the whole, to serve efficiency and velocity while giving the an exaggerated notion of insight, meaning, and value. The notion of the topology of data, insight, and knowledge more or less becomes hidden and buried in the mix. Solutions to this circumstances are not radical alternatives [but] as much as they are ... 


Working with Airflow given my previous heavy interest in semantic data...

Companies, institutions, people spend lots of time and effort gathering and structuring somewhat reliable data, and the methods we decide to employ in order to wrangle it largely go against what information lies in their original structure.

- plethora of structured, and semi-structured data
- silo'd

## -

Serve as a great example of what kind of models can come out of such a strong bedding.

- NVD's and MITRE's datasets interested me in their interoperability (in obvious addition to sheer size).

As someone who wants to learn, I prefer tinkering myself

- massive amounts of data
- similarly structured
- similar domains
- makes it an easy candidate for graph processing*

To notify, inform solutions, to build off of.

## Goals

- Data Enrichment
- Easier manual and automated semantic navigation of large datasets
- Business Continuity
- Increase operational efficiency

## Conditions that Need to Be Met

## Mini WBS

- [ ] Create single api dag run

### Technologies

Semantic Data, REST APIs

## Service / Workflow Architectural Components

The core of this app, as is the core of a behemoth multitude of workflow automation apps and services, is Apache Airflow.

- Particularly in infosec and security automation
  1. Centralized workflow and logging
- giving way to centralized monitoring, efficient observability and monitoring.

## Package structure

While conceptualizing, prototyping, and iterating over any solution implementations within a given problem-space, the simplest implementations are often most self-advised. This way, I can focus on a larger idea without losing bandwidth in any attemps to perfect some component implementation.

### Ontologies

#### Keywords

### Meta

#### What I Would Have Done Differently
